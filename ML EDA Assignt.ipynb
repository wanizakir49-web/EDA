{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae58b8cc",
   "metadata": {},
   "source": [
    "# DA-AG-007 — Foundations of Machine Learning and EDA\n",
    "Submitted by - Mohd Khalil\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aee5a5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T09:03:02.246705Z",
     "iopub.status.busy": "2025-10-28T09:03:02.246328Z",
     "iopub.status.idle": "2025-10-28T09:03:02.257520Z",
     "shell.execute_reply": "2025-10-28T09:03:02.256829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using local datasets:\n",
      "/mnt/data/googleplaystore.csv\n",
      "/mnt/data/titanic.csv\n",
      "/mnt/data/flight_price.csv\n",
      "/mnt/data/hr_analytics.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- Injected cell: use local CSVs ---\n",
    "googleplay_local = '/mnt/data/googleplaystore.csv'\n",
    "titanic_local = '/mnt/data/titanic.csv'\n",
    "flight_local = '/mnt/data/flight_price.csv'\n",
    "hr_local = '/mnt/data/hr_analytics.csv'\n",
    "\n",
    "\n",
    "url = googleplay_local\n",
    "titanic_url = titanic_local\n",
    "flight_url = flight_local\n",
    "hr_url = hr_local\n",
    "\n",
    "print('Using local datasets:')\n",
    "print(url)\n",
    "print(titanic_url)\n",
    "print(flight_url)\n",
    "print(hr_url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "454dfa9e",
   "metadata": {},
   "source": [
    "### Question 1: Difference between AI, ML, DL, and Data Science\n",
    "\n",
    "**AI (Artificial Intelligence)** — broad field focused on creating systems that perform tasks that normally require human intelligence. Scope: reasoning, planning, language, perception. Techniques: search algorithms, knowledge representation, rule-based systems, ML. Applications: autonomous vehicles, chatbots, recommendation systems.\n",
    "\n",
    "**ML (Machine Learning)** — a subset of AI where systems learn patterns from data. Scope: supervised, unsupervised, reinforcement learning. Techniques: linear/logistic regression, decision trees, SVM, ensemble methods. Applications: classification, regression, clustering, anomaly detection.\n",
    "\n",
    "**DL (Deep Learning)** — a subset of ML that uses neural networks with many layers (deep networks). Scope: representation learning from raw data. Techniques: CNNs, RNNs, Transformers. Applications: image recognition, NLP, speech, generative models.\n",
    "\n",
    "**Data Science** — interdisciplinary field combining domain knowledge, statistics, and computing to extract insights from data. Scope: data cleaning, EDA, modeling, visualization, deployment. Techniques: statistics, ML, data engineering, storytelling. Applications: business intelligence, product analytics, scientific research.\n",
    "\n",
    "Key differences:\n",
    "- Scope: AI (broadest) → ML (subset) → DL (subset of ML). Data Science overlaps with all and focuses on the data-to-insight pipeline.\n",
    "- Techniques: AI includes symbolic approaches; ML focuses on learning algorithms; DL uses deep neural nets; Data Science includes statistics and engineering.\n",
    "- Applications: AI for general automation; ML/DL for predictive tasks; Data Science for analysis and decision support.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837cd2c2",
   "metadata": {},
   "source": [
    "### Question 2: Overfitting and Underfitting\n",
    "\n",
    "**Overfitting**: A model learns noise and idiosyncrasies of training data, performing well on training but poorly on unseen data. Symptoms: large gap between training and validation error.\n",
    "\n",
    "**Underfitting**: A model is too simple to capture underlying patterns, showing poor performance on both training and validation data. Symptoms: high training error.\n",
    "\n",
    "**Bias-Variance Tradeoff**:\n",
    "- High bias → underfitting (model too simple).\n",
    "- High variance → overfitting (model too complex).\n",
    "\n",
    "**Detection**:\n",
    "- Plot learning curves (training vs validation error as function of training set size or model complexity).\n",
    "- Cross-validation scores: large variance across folds indicates overfitting.\n",
    "\n",
    "**Prevention / Remedies**:\n",
    "- Regularization (L1/L2) to penalize large weights.\n",
    "- Use simpler models or reduce model complexity to combat overfitting.\n",
    "- Increase training data or use data augmentation.\n",
    "- Early stopping during training when validation loss stops improving.\n",
    "- Cross-validation (k-fold) to get robust estimate of generalization.\n",
    "- Ensembling (bagging) to reduce variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7c0825",
   "metadata": {},
   "source": [
    "### Question 3: Handling Missing Values (3 methods)\n",
    "\n",
    "1. **Deletion (listwise or pairwise)**\n",
    "   - Drop rows (`df.dropna()`) or columns with missing values.\n",
    "   - Pros: simple, preserves observed values.\n",
    "   - Cons: loses data; biased if missingness is not completely at random.\n",
    "\n",
    "2. **Simple imputation (mean/median/mode)**\n",
    "   - Replace numeric NaNs with column mean/median; categorical with mode.\n",
    "   - Example: `df['age'].fillna(df['age'].median(), inplace=True)`.\n",
    "   - Pros: easy and fast.\n",
    "   - Cons: underestimates variance and may introduce bias.\n",
    "\n",
    "3. **Predictive modeling / advanced imputation**\n",
    "   - Use a model (KNNImputer, IterativeImputer / MICE) to predict missing values from other features.\n",
    "   - Example: scikit-learn `IterativeImputer` or `KNNImputer`.\n",
    "   - Pros: often more accurate; preserves relationships between features.\n",
    "   - Cons: more complex and computationally intensive.\n",
    "\n",
    "Other considerations:\n",
    "- Always analyze missingness mechanism (MCAR, MAR, MNAR).\n",
    "- Consider adding a missingness indicator column (`df['age_missing']=df['age'].isnull().astype(int)`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a234557f",
   "metadata": {},
   "source": [
    "### Question 4: Imbalanced Dataset\n",
    "\n",
    "An imbalanced dataset is one where class labels are not represented equally (e.g., fraud detection where positive cases are rare). Problems: classifiers can be biased towards majority class; evaluation metrics like accuracy become misleading.\n",
    "\n",
    "Techniques:\n",
    "- **SMOTE (Synthetic Minority Over-sampling Technique)**: generates synthetic examples of the minority class by interpolating between minority neighbors. Practical: `imblearn.over_sampling.SMOTE()`.\n",
    "- **Random undersampling / oversampling**: Remove samples from majority (undersample) or duplicate minority samples (oversample). Practical: `RandomUnderSampler`, `RandomOverSampler` in `imblearn`.\n",
    "- **Class weights**: Set `class_weight='balanced'` in models like `LogisticRegression`, `RandomForestClassifier` to penalize mistakes on minority class more.\n",
    "\n",
    "When to use which:\n",
    "- If you have plenty of majority data: undersample.\n",
    "- If small dataset: SMOTE or class weights to avoid information loss.\n",
    "- Always evaluate with metrics suited to imbalance: precision-recall, F1, ROC AUC, PR AUC, confusion matrix, and use cross-validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6b13d5",
   "metadata": {},
   "source": [
    "### Question 5: Feature Scaling — Min-Max vs Standardization\n",
    "\n",
    "Feature scaling is important because many ML algorithms (KNN, SVM, K-means, gradient-based models) use distances or assume features are on comparable scales. Without scaling, features with larger magnitudes dominate.\n",
    "\n",
    "**Min-Max scaling (Normalization)**\n",
    "- Transforms features to a fixed range, usually [0, 1]: `X_scaled = (X - X.min) / (X.max - X.min)`.\n",
    "- Preserves shape of original distribution (doesn't change variance relationships).\n",
    "- Sensitive to outliers (outliers will be squashed to extremes).\n",
    "\n",
    "**Standardization (Z-score)**\n",
    "- Centers features to mean 0 with standard deviation 1: `X_scaled = (X - X.mean) / X.std()`.\n",
    "- Less sensitive to outliers than Min-Max for some algorithms; does not bound values.\n",
    "- Preferred for algorithms that assume zero-centered data (e.g., PCA, linear models).\n",
    "\n",
    "Which to use:\n",
    "- Use **Min-Max** when you need features within a bounded interval (e.g., neural network inputs when activations are sensitive).\n",
    "- Use **Standardization** for algorithms like SVM, logistic regression, PCA, or when outliers exist.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad36804",
   "metadata": {},
   "source": [
    "### Question 6: Label Encoding vs One-Hot Encoding\n",
    "\n",
    "**Label Encoding**\n",
    "- Converts categories to integer labels (0..k-1).\n",
    "- Use when categories are ordinal (e.g., `low < medium < high`).\n",
    "- Danger: some models may infer a spurious ordinal relationship when applied to nominal categories.\n",
    "\n",
    "**One-Hot Encoding**\n",
    "- Creates binary columns for each category using `pd.get_dummies()` or `OneHotEncoder`.\n",
    "- Use for nominal categorical variables with no ordinal relationship.\n",
    "- Can create high-dimensional feature spaces for categories with many unique values (use hashing or embeddings in that case).\n",
    "\n",
    "When to prefer which:\n",
    "- Ordinal categories → Label Encoding.\n",
    "- Nominal categories with few unique values → One-Hot Encoding.\n",
    "- High-cardinality nominal features → Target encoding, frequency encoding, or embeddings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f206d4c",
   "metadata": {},
   "source": [
    "## Question 7: Google Play Store Dataset\n",
    "\n",
    "### (a) Analyze relationship between app categories and ratings\n",
    "\n",
    "Below is a runnable analysis. Run the cell to read `googleplaystore.csv` from the MasteriNeuron repo and calculate average ratings per category.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80e1a425",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-28T09:03:02.263083Z",
     "iopub.status.busy": "2025-10-28T09:03:02.262755Z",
     "iopub.status.idle": "2025-10-28T09:03:05.407784Z",
     "shell.execute_reply": "2025-10-28T09:03:05.405215Z"
    }
   },
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error [Errno -3] Temporary failure in name resolution>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mgaierror\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/urllib/request.py:1348\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1347\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1348\u001b[39m     \u001b[43mh\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mselector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1349\u001b[39m \u001b[43m              \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhas_header\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mTransfer-encoding\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1350\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/http/client.py:1298\u001b[39m, in \u001b[36mHTTPConnection.request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1297\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1298\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/http/client.py:1344\u001b[39m, in \u001b[36mHTTPConnection._send_request\u001b[39m\u001b[34m(self, method, url, body, headers, encode_chunked)\u001b[39m\n\u001b[32m   1343\u001b[39m     body = _encode(body, \u001b[33m'\u001b[39m\u001b[33mbody\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1344\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mendheaders\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/http/client.py:1293\u001b[39m, in \u001b[36mHTTPConnection.endheaders\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1292\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[32m-> \u001b[39m\u001b[32m1293\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_output\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencode_chunked\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/http/client.py:1052\u001b[39m, in \u001b[36mHTTPConnection._send_output\u001b[39m\u001b[34m(self, message_body, encode_chunked)\u001b[39m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m._buffer[:]\n\u001b[32m-> \u001b[39m\u001b[32m1052\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1055\u001b[39m \n\u001b[32m   1056\u001b[39m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/http/client.py:990\u001b[39m, in \u001b[36mHTTPConnection.send\u001b[39m\u001b[34m(self, data)\u001b[39m\n\u001b[32m    989\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_open:\n\u001b[32m--> \u001b[39m\u001b[32m990\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    991\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/http/client.py:1463\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1461\u001b[39m \u001b[33m\"\u001b[39m\u001b[33mConnect to a host on a given (SSL) port.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1463\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1465\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tunnel_host:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/http/client.py:956\u001b[39m, in \u001b[36mHTTPConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    955\u001b[39m sys.audit(\u001b[33m\"\u001b[39m\u001b[33mhttp.client.connect\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m.port)\n\u001b[32m--> \u001b[39m\u001b[32m956\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_create_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    957\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    958\u001b[39m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/socket.py:827\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, all_errors)\u001b[39m\n\u001b[32m    826\u001b[39m exceptions = []\n\u001b[32m--> \u001b[39m\u001b[32m827\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSOCK_STREAM\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    828\u001b[39m     af, socktype, proto, canonname, sa = res\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/socket.py:962\u001b[39m, in \u001b[36mgetaddrinfo\u001b[39m\u001b[34m(host, port, family, type, proto, flags)\u001b[39m\n\u001b[32m    961\u001b[39m addrlist = []\n\u001b[32m--> \u001b[39m\u001b[32m962\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_socket\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetaddrinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfamily\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    963\u001b[39m     af, socktype, proto, canonname, sa = res\n",
      "\u001b[31mgaierror\u001b[39m: [Errno -3] Temporary failure in name resolution",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mURLError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m url = \u001b[33m'\u001b[39m\u001b[33mhttps://raw.githubusercontent.com/MasteriNeuron/datasets/main/googleplaystore.csv\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mLoaded googleplaystore.csv — shape:\u001b[39m\u001b[33m'\u001b[39m, df.shape)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Basic cleaning: ensure Rating is numeric\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[39m, in \u001b[36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    210\u001b[39m         kwargs[new_arg_name] = new_arg_value\n\u001b[32m--> \u001b[39m\u001b[32m211\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[39m, in \u001b[36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > num_allow_args:\n\u001b[32m    326\u001b[39m     warnings.warn(\n\u001b[32m    327\u001b[39m         msg.format(arguments=_format_argument_list(allow_args)),\n\u001b[32m    328\u001b[39m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[32m    329\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m    330\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[39m\n\u001b[32m    935\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m    936\u001b[39m     dialect,\n\u001b[32m    937\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    946\u001b[39m     defaults={\u001b[33m\"\u001b[39m\u001b[33mdelimiter\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m    947\u001b[39m )\n\u001b[32m    948\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m--> \u001b[39m\u001b[32m950\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    602\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    604\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m605\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    607\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    608\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1439\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1441\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1442\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1735\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1733\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1734\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1735\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1736\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1737\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1738\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1739\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1740\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1741\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1742\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1743\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1744\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1745\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1746\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/common.py:713\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    710\u001b[39m     codecs.lookup_error(errors)\n\u001b[32m    712\u001b[39m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m713\u001b[39m ioargs = \u001b[43m_get_filepath_or_buffer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    714\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    715\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    716\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    717\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    718\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    719\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    721\u001b[39m handle = ioargs.filepath_or_buffer\n\u001b[32m    722\u001b[39m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/common.py:363\u001b[39m, in \u001b[36m_get_filepath_or_buffer\u001b[39m\u001b[34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[39m\n\u001b[32m    361\u001b[39m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[32m    362\u001b[39m req_info = urllib.request.Request(filepath_or_buffer, headers=storage_options)\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq_info\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[32m    364\u001b[39m     content_encoding = req.headers.get(\u001b[33m\"\u001b[39m\u001b[33mContent-Encoding\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    365\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding == \u001b[33m\"\u001b[39m\u001b[33mgzip\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    366\u001b[39m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.11/site-packages/pandas/io/common.py:265\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    259\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[33;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[32m    261\u001b[39m \u001b[33;03mthe stdlib.\u001b[39;00m\n\u001b[32m    262\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    263\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01murllib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrequest\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m265\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43murllib\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/urllib/request.py:216\u001b[39m, in \u001b[36murlopen\u001b[39m\u001b[34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[39m\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    215\u001b[39m     opener = _opener\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mopener\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/urllib/request.py:519\u001b[39m, in \u001b[36mOpenerDirector.open\u001b[39m\u001b[34m(self, fullurl, data, timeout)\u001b[39m\n\u001b[32m    516\u001b[39m     req = meth(req)\n\u001b[32m    518\u001b[39m sys.audit(\u001b[33m'\u001b[39m\u001b[33murllib.Request\u001b[39m\u001b[33m'\u001b[39m, req.full_url, req.data, req.headers, req.get_method())\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n\u001b[32m    522\u001b[39m meth_name = protocol+\u001b[33m\"\u001b[39m\u001b[33m_response\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/urllib/request.py:536\u001b[39m, in \u001b[36mOpenerDirector._open\u001b[39m\u001b[34m(self, req, data)\u001b[39m\n\u001b[32m    533\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    535\u001b[39m protocol = req.type\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_chain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhandle_open\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprotocol\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\n\u001b[32m    537\u001b[39m \u001b[43m                          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m_open\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    538\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result:\n\u001b[32m    539\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/urllib/request.py:496\u001b[39m, in \u001b[36mOpenerDirector._call_chain\u001b[39m\u001b[34m(self, chain, kind, meth_name, *args)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[32m    495\u001b[39m     func = \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[32m--> \u001b[39m\u001b[32m496\u001b[39m     result = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    497\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    498\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/urllib/request.py:1391\u001b[39m, in \u001b[36mHTTPSHandler.https_open\u001b[39m\u001b[34m(self, req)\u001b[39m\n\u001b[32m   1390\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[32m-> \u001b[39m\u001b[32m1391\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHTTPSConnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1392\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_check_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/local/lib/python3.11/urllib/request.py:1351\u001b[39m, in \u001b[36mAbstractHTTPHandler.do_open\u001b[39m\u001b[34m(self, http_class, req, **http_conn_args)\u001b[39m\n\u001b[32m   1348\u001b[39m         h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[32m   1349\u001b[39m                   encode_chunked=req.has_header(\u001b[33m'\u001b[39m\u001b[33mTransfer-encoding\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m   1350\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1351\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[32m   1352\u001b[39m     r = h.getresponse()\n\u001b[32m   1353\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[31mURLError\u001b[39m: <urlopen error [Errno -3] Temporary failure in name resolution>"
     ]
    }
   ],
   "source": [
    "# Q7: Google Play Store — Category vs Rating analysis\n",
    "import pandas as pd\n",
    "url = 'https://raw.githubusercontent.com/MasteriNeuron/datasets/main/googleplaystore.csv'\n",
    "df = pd.read_csv(url)\n",
    "print('Loaded googleplaystore.csv — shape:', df.shape)\n",
    "\n",
    "# Basic cleaning: ensure Rating is numeric\n",
    "df['Rating'] = pd.to_numeric(df['Rating'], errors='coerce')\n",
    "cat_rating = df.groupby('Category')['Rating'].agg(['count','mean','median','std']).sort_values('mean', ascending=False)\n",
    "display(cat_rating.head(10))\n",
    "\n",
    "# Example insight lines (replace with actual output after running):\n",
    "# - Categories with highest average ratings might include 'ART_AND_DESIGN', 'BOOKS_AND_REFERENCE' etc.\n",
    "# - Categories with lowest average ratings often include apps where utility is critical or many low-quality apps exist.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da02c0e",
   "metadata": {},
   "source": [
    "## Question 8: Titanic Dataset\n",
    "\n",
    "### (a) Survival rates by passenger class (Pclass)\n",
    "### (b) Survival by age group (children <18 vs adults ≥18)\n",
    "\n",
    "Run the following cell to load `titanic.csv` and compute the requested statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bd2fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8: Titanic analysis\n",
    "import pandas as pd\n",
    "titanic_url = 'https://raw.githubusercontent.com/MasteriNeuron/datasets/main/titanic.csv'\n",
    "t = pd.read_csv(titanic_url)\n",
    "print('Loaded titanic.csv — shape:', t.shape)\n",
    "\n",
    "# Ensure column names include 'Survived' and 'Pclass' and 'Age'\n",
    "t['Age'] = pd.to_numeric(t['Age'], errors='coerce')\n",
    "survival_by_class = t.groupby('Pclass')['Survived'].mean().sort_values(ascending=False)\n",
    "display(survival_by_class)\n",
    "\n",
    "# Children vs adults\n",
    "t['is_child'] = t['Age'] < 18\n",
    "survival_by_agegroup = t.groupby('is_child')['Survived'].mean()\n",
    "display(survival_by_agegroup)\n",
    "\n",
    "# Example conclusions (after running):\n",
    "# - Historically, first-class passengers had the highest survival rate.\n",
    "# - Children often had a higher survival rate than adults due to 'women and children first' evacuation practices.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d463c4",
   "metadata": {},
   "source": [
    "## Question 9: Flight Price Prediction Dataset\n",
    "\n",
    "### (a) Price vs days left until departure — identify surges and recommend booking window.\n",
    "### (b) Compare prices across airlines for a route (e.g., Delhi-Mumbai).\n",
    "Run the cell below to analyze `flight_price.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7af9ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9: Flight price analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "flight_url = 'https://raw.githubusercontent.com/MasteriNeuron/datasets/main/flight_price.csv'\n",
    "fp = pd.read_csv(flight_url)\n",
    "print('Loaded flight_price.csv — shape:', fp.shape)\n",
    "\n",
    "# Example preprocessing: convert date columns or days_left if present\n",
    "if 'days_left' in fp.columns:\n",
    "    days_price = fp.groupby('days_left')['price'].agg(['count','mean','median']).reset_index()\n",
    "    display(days_price.head(20))\n",
    "else:\n",
    "    print('Column days_left not present — inspect dataset for date fields and compute days until departure first.')\n",
    "\n",
    "# Compare airlines for a route (example: Delhi-Mumbai)\n",
    "route = fp[(fp['source']=='Delhi') & (fp['destination']=='Mumbai')] if {'source','destination'}.issubset(fp.columns) else pd.DataFrame()\n",
    "if not route.empty:\n",
    "    airline_cmp = route.groupby('airline')['price'].agg(['count','mean','median']).sort_values('mean')\n",
    "    display(airline_cmp)\n",
    "else:\n",
    "    print('Route columns not found or no matching route — inspect columns:', fp.columns.tolist())\n",
    "\n",
    "# Example recommendation (after plotting mean price vs days_left):\n",
    "# - Often prices are lower when booking 30-60 days in advance; exponential surges commonly occur within last 7-14 days before departure.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5cf59a",
   "metadata": {},
   "source": [
    "## Question 10: HR Analytics Dataset\n",
    "\n",
    "### (a) Factors correlated with attrition\n",
    "### (b) Relationship: number of projects vs attrition\n",
    "Run the cell below to analyze `hr_analytics.csv`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641f28af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10: HR Analytics\n",
    "import pandas as pd\n",
    "hr_url = 'https://raw.githubusercontent.com/MasteriNeuron/datasets/main/hr_analytics.csv'\n",
    "hr = pd.read_csv(hr_url)\n",
    "print('Loaded hr_analytics.csv — shape:', hr.shape)\n",
    "\n",
    "# Example columns often present: 'Attrition' or 'left', 'satisfaction_level', 'number_project', 'average_montly_hours','time_spend_company','salary','Work_accident','promotion_last_5years'\n",
    "display(hr.head())\n",
    "\n",
    "# Convert attrition to binary if needed\n",
    "if 'left' in hr.columns:\n",
    "    hr['attrition'] = hr['left']\n",
    "elif 'Attrition' in hr.columns:\n",
    "    hr['attrition'] = hr['Attrition'].map({ 'Yes':1, 'No':0 }) if hr['Attrition'].dtype == object else hr['Attrition']\n",
    "else:\n",
    "    print('No obvious attrition column found; please inspect column names:', hr.columns.tolist())\n",
    "\n",
    "# Correlation with attrition\n",
    "if 'attrition' in hr.columns:\n",
    "    numeric_cols = hr.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    corr = hr[numeric_cols].corr()['attrition'].sort_values(ascending=False)\n",
    "    display(corr)\n",
    "    \n",
    "    # Relationship between number of projects and attrition\n",
    "    if 'number_project' in hr.columns:\n",
    "        proj = hr.groupby('number_project')['attrition'].mean().reset_index().sort_values('number_project')\n",
    "        display(proj)\n",
    "else:\n",
    "    print('Cannot compute correlations without attrition column.')\n",
    "\n",
    "# Example findings (after running):\n",
    "# - Low satisfaction_level, high average_monthly_hours, and overtime often correlate with higher attrition.\n",
    "# - There may or may not be a monotonic relationship between number_of_projects and attrition (sometimes too many projects -> burnout -> higher attrition).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833c3ca6",
   "metadata": {},
   "source": [
    "----\n",
    "### Notes & next steps\n",
    "- The notebook contains **runnable** code cells that read data from `https://raw.githubusercontent.com/MasteriNeuron/datasets/main/`.\n",
    "- **I couldn't execute the cells here** because the execution environment for this notebook builder does not have internet access. To obtain real outputs, run the notebook cells in a Jupyter environment with internet access (e.g., your laptop, Google Colab, or Binder).\n",
    "- If you prefer, upload the CSV files here and I will run the analysis in this environment and produce the executed notebook with real outputs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aab5c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Q7 plot: Average Rating by Category (top and bottom 10)\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv(url)\n",
    "df['Rating'] = pd.to_numeric(df['Rating'], errors='coerce')\n",
    "cat_rating = df.groupby('Category')['Rating'].agg(['count','mean']).sort_values('mean', ascending=False)\n",
    "top10 = cat_rating.head(10)\n",
    "bottom10 = cat_rating.tail(10)\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "top10['mean'].plot(kind='bar')\n",
    "plt.title('Top 10 Categories by Average Rating')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c838b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Q8 plots: Survival by Pclass and by age group\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "t = pd.read_csv(titanic_url)\n",
    "t['Age'] = pd.to_numeric(t['Age'], errors='coerce')\n",
    "survival_by_class = t.groupby('Pclass')['Survived'].mean().sort_index()\n",
    "plt.figure(figsize=(6,4))\n",
    "survival_by_class.plot(kind='bar')\n",
    "plt.title('Survival Rate by Pclass')\n",
    "plt.ylabel('Survival Rate')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "t['is_child'] = t['Age'] < 18\n",
    "survival_by_age = t.groupby('is_child')['Survived'].mean()\n",
    "plt.figure(figsize=(4,4))\n",
    "survival_by_age.plot(kind='bar')\n",
    "plt.title('Survival: Children (<18) vs Adults (>=18)')\n",
    "plt.ylabel('Survival Rate')\n",
    "plt.xticks([0,1], ['Adults','Children'])\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e2160c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Q9 plots: Price vs days_left and airline comparison for a route (if available)\n",
    "import pandas as pd, matplotlib.pyplot as plt\n",
    "fp = pd.read_csv(flight_url)\n",
    "# ensure lowercase column names for flexibility\n",
    "cols = [c.lower() for c in fp.columns]\n",
    "fp.columns = cols\n",
    "if 'days_left' in fp.columns and 'price' in fp.columns:\n",
    "    days_price = fp.groupby('days_left')['price'].mean().reset_index()\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.plot(days_price['days_left'], days_price['price'], marker='o')\n",
    "    plt.gca().invert_xaxis()  # often days_left decreases towards departure; invert for readability\n",
    "    plt.title('Average Price vs Days Left to Departure')\n",
    "    plt.xlabel('Days left')\n",
    "    plt.ylabel('Average Price')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print('No days_left or price columns found. Found columns:', fp.columns.tolist())\n",
    "\n",
    "# Airline comparison for route: try common column names\n",
    "if {'source','destination','airline','price'}.issubset(fp.columns):\n",
    "    route = fp[(fp['source'].str.lower()=='delhi') & (fp['destination'].str.lower()=='mumbai')]\n",
    "    if not route.empty:\n",
    "        airline_cmp = route.groupby('airline')['price'].mean().sort_values()\n",
    "        plt.figure(figsize=(8,4))\n",
    "        airline_cmp.plot(kind='bar')\n",
    "        plt.title('Average Price by Airline (Delhi -> Mumbai)')\n",
    "        plt.ylabel('Average Price')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print('No Delhi-Mumbai rows found in dataset.')\n",
    "else:\n",
    "    print('Route comparison columns missing; available columns:', fp.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f13076",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Q10 plots: Correlation of numeric features with attrition and number_project vs attrition\n",
    "import pandas as pd, matplotlib.pyplot as plt\n",
    "hr = pd.read_csv(hr_url)\n",
    "# normalize column names\n",
    "hr.columns = [c.strip() for c in hr.columns]\n",
    "# identify attrition column\n",
    "if 'left' in hr.columns:\n",
    "    hr['attrition'] = hr['left']\n",
    "elif 'Attrition' in hr.columns:\n",
    "    try:\n",
    "        hr['attrition'] = hr['Attrition'].map({'Yes':1,'No':0})\n",
    "    except:\n",
    "        hr['attrition'] = hr['Attrition']\n",
    "elif 'attrition' in hr.columns:\n",
    "    pass\n",
    "else:\n",
    "    # Try common alternatives\n",
    "    for alt in ['left','target','resigned']:\n",
    "        if alt in hr.columns:\n",
    "            hr['attrition'] = hr[alt]\n",
    "            break\n",
    "\n",
    "if 'attrition' in hr.columns:\n",
    "    numeric_cols = hr.select_dtypes(include=['number']).columns.tolist()\n",
    "    if 'attrition' in numeric_cols:\n",
    "        numeric_cols.remove('attrition')\n",
    "    corr = hr[numeric_cols + ['attrition']].corr()['attrition'].abs().sort_values(ascending=False)\n",
    "    display(corr.head(10))\n",
    "    # plot top 3 correlated numeric features vs attrition\n",
    "    top_feats = corr.index[:3].tolist()\n",
    "    for feat in top_feats:\n",
    "        plt.figure(figsize=(6,4))\n",
    "        # scatter with jitter for categorical-like numeric features\n",
    "        plt.scatter(hr[feat], hr['attrition'], alpha=0.3)\n",
    "        plt.xlabel(feat)\n",
    "        plt.ylabel('Attrition')\n",
    "        plt.title(f'{feat} vs Attrition')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "else:\n",
    "    print('Attrition-like column not found. Columns:', hr.columns.tolist())\n",
    "\n",
    "# number_project vs attrition mean plot\n",
    "if 'number_project' in hr.columns and 'attrition' in hr.columns:\n",
    "    proj = hr.groupby('number_project')['attrition'].mean().reset_index()\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.plot(proj['number_project'], proj['attrition'], marker='o')\n",
    "    plt.xlabel('Number of Projects')\n",
    "    plt.ylabel('Attrition Rate (mean)')\n",
    "    plt.title('Attrition Rate by Number of Projects')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
